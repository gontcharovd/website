---
title: "Scala 3 and Spark Compatibility"
date: '2025-07-26'
issueno: "022"
draft: false
---

I was experimenting with the new Scala 3 macro syntax and getting errors even though my code was clearly correct:

```scala
val msg = Expr("Hello")
val printHello = '{ print($msg) }
println(printHello.show) // print("Hello")
```

I soon figured out that the Scala version in my Spark sbt project was 2.12.17 - so version 2. Looking at the [Spark compatibility matrix](https://community.cloudera.com/t5/Community-Articles/Spark-Scala-Version-Compatibility-Matrix/ta-p/383713) I saw that Spark doesn't support Scala 3 yet!

This is a known issue, but someone already found a [workaround](https://xebia.com/blog/using-scala-3-with-spark/) using `.map(_.cross(CrossVersion.for3Use2_13))` in my *build.sbt* file:

```
name := "spark-learning"

version := "0.1"
scalaVersion := "3.3.3"

val sparkVersion = "4.0.0"  // Use latest Spark version

libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % sparkVersion,
  "org.apache.spark" %% "spark-sql" % sparkVersion
).map(_.cross(CrossVersion.for3Use2_13))
```

# Datasets

Upgrading to Scala 3 lead to the following error:

```
[error] 40 |  val iot_ds = silver_df.as[IOTDataTypes]
[error]    |                                         ^
[error]    |Unable to find encoder for type sparklearning.IOTDataTypes. An implicit Encoder[sparklearning.IOTDataTypes] is needed to store sparklearning.IOTDataTypes instances in a Dataset. Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._  Support for serializing other types will be added in future releases..
```

This could be solved by adding the following dependency in my *build.sbt* file:

```
"org.scala-lang" %% "scala3-library" % scalaVersion.value
```

I updated my *datasets.scala* code as follows:

```scala
case class Usage(uid: Int, user: String, usage: Int)
case class UsageCost(uid: Int, user: String, usage: Int, cost: Double)

// Correct way to create TypeTags in Scala 3
import scala.reflect.runtime.universe._

implicit val usageTypeTag: TypeTag[Usage] = typeTag[Usage]
implicit val usageCostTypeTag: TypeTag[UsageCost] = typeTag[UsageCost]

// Create explicit encoders (these should work now with TypeTags)
implicit val usageEncoder: Encoder[Usage] = Encoders.product[Usage]
implicit val usageCostEncoder: Encoder[UsageCost] = Encoders.product[UsageCost]
```

The code now compiles but I'm encountering an error:

```
Exception in thread "sbt-bg-threads-5" java.lang.ExceptionInInitializerError
        at sparklearning.Datasets.main(datasets.scala)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:569)
        at sbt.Run.invokeMain(Run.scala:135)
        at sbt.Run.execute$1(Run.scala:85)
        at sbt.Run.$anonfun$runWithLoader$5(Run.scala:112)
        at sbt.Run$.executeSuccess(Run.scala:178)
        at sbt.Run.runWithLoader(Run.scala:112)
        at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:2091)
        at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:2030)
        at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
        at scala.util.Try$.apply(Try.scala:213)
        at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:378)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NullPointerException: Cannot invoke "scala.reflect.api.TypeTags$TypeTag.in(scala.reflect.api.Mirror)" because the return value of "scala.reflect.api.TypeTags.typeTag(scala.reflect.api.TypeTags$TypeTag)" is null
        at org.apache.spark.sql.catalyst.ScalaReflection$.encoderFor(ScalaReflection.scala:236)
        at org.apache.spark.sql.Encoders$.product(Encoders.scala:319)
        at sparklearning.Datasets$.<clinit>(datasets.scala:25)
        ... 18 more
```
